{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Improvement: Advanced Techniques for Higher Accuracy\n",
    "\n",
    "This notebook implements several advanced techniques to improve model accuracy:\n",
    "1. Multiple model comparison (Logistic Regression, Random Forest, XGBoost, SVM)\n",
    "2. Hyperparameter tuning with GridSearchCV\n",
    "3. Ensemble methods (Voting Classifier)\n",
    "4. Feature selection\n",
    "5. Cross-validation for robust evaluation\n",
    "6. Better feature engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK resources\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    nltk.download('omw-1.4', quiet=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text) or text is None:\n",
    "        return ''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", '', text)\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (7730, 4)\n",
      "Label distribution:\n",
      "is_depression\n",
      "0    3900\n",
      "1    3830\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set base directory\n",
    "base_dir = 'D:/mental_health_detector'\n",
    "\n",
    "# Load data\n",
    "data_path = os.path.join(base_dir, 'data/processed/depression_dataset_processed.csv')\n",
    "raw_data_path = os.path.join(base_dir, 'data/raw/depression_dataset_reddit_cleaned.csv')\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    if 'processed_text' not in df.columns:\n",
    "        df['processed_text'] = df['clean_text'].apply(preprocess_text)\n",
    "else:\n",
    "    df = pd.read_csv(raw_data_path)\n",
    "    df['processed_text'] = df['clean_text'].apply(preprocess_text)\n",
    "\n",
    "# Clean data\n",
    "df = df[df['processed_text'].notna() & (df['processed_text'].str.strip() != '')]\n",
    "df = df[df['is_depression'].notna()]\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Label distribution:\")\n",
    "print(df['is_depression'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Enhanced Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (7730, 8000)\n",
      "Number of features: 8000\n"
     ]
    }
   ],
   "source": [
    "# Enhanced TF-IDF with better parameters\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=8000,  # Increased from 5000\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,  # Ignore terms that appear in less than 2 documents\n",
    "    max_df=0.95,  # Ignore terms that appear in more than 95% of documents\n",
    "    sublinear_tf=True  # Apply sublinear tf scaling (1 + log(tf))\n",
    ")\n",
    "\n",
    "processed_texts = df['processed_text'].fillna('').astype(str).tolist()\n",
    "X_tfidf = vectorizer.fit_transform(processed_texts)\n",
    "y = df['is_depression'].values\n",
    "\n",
    "print(f\"Feature matrix shape: {X_tfidf.shape}\")\n",
    "print(f\"Number of features: {X_tfidf.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Selection (Optional - can improve accuracy by removing noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features: 8000\n",
      "Selected features: 6000\n"
     ]
    }
   ],
   "source": [
    "# Feature selection - select top k features using chi2\n",
    "# This can help remove noise and improve accuracy\n",
    "k_best = 6000  # Select top 6000 features\n",
    "selector = SelectKBest(chi2, k=min(k_best, X_tfidf.shape[1]))\n",
    "X_selected = selector.fit_transform(X_tfidf, y)\n",
    "\n",
    "print(f\"Original features: {X_tfidf.shape[1]}\")\n",
    "print(f\"Selected features: {X_selected.shape[1]}\")\n",
    "\n",
    "# Use selected features\n",
    "X = X_selected\n",
    "# Or use all features: X = X_tfidf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train-Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 6184\n",
      "Test samples: 1546\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison - Test Multiple Algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models with 5-fold cross-validation...\n",
      "\n",
      "Logistic Regression: 0.9531 (+/- 0.0141)\n",
      "Random Forest: 0.8984 (+/- 0.0144)\n",
      "XGBoost: 0.9544 (+/- 0.0125)\n",
      "SVM: 0.9559 (+/- 0.0149)\n",
      "Gradient Boosting: 0.9486 (+/- 0.0180)\n",
      "Naive Bayes: 0.9125 (+/- 0.0197)\n",
      "\n",
      "Best model: SVM with CV accuracy: 0.9559\n"
     ]
    }
   ],
   "source": [
    "# Define models to test\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=2000, random_state=42, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42, class_weight='balanced', n_jobs=-1),\n",
    "    'XGBoost': xgb.XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42, eval_metric='logloss'),\n",
    "    'SVM': SVC(kernel='linear', probability=True, random_state=42, class_weight='balanced'),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42),\n",
    "    'Naive Bayes': MultinomialNB(alpha=0.1)\n",
    "}\n",
    "\n",
    "# Evaluate each model with cross-validation\n",
    "results = {}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"Evaluating models with 5-fold cross-validation...\\n\")\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    results[name] = {\n",
    "        'mean_score': scores.mean(),\n",
    "        'std_score': scores.std(),\n",
    "        'model': model\n",
    "    }\n",
    "    print(f\"{name}: {scores.mean():.4f} (+/- {scores.std()*2:.4f})\")\n",
    "\n",
    "# Find best model\n",
    "best_model_name = max(results, key=lambda x: results[x]['mean_score'])\n",
    "print(f\"\\nBest model: {best_model_name} with CV accuracy: {results[best_model_name]['mean_score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Tuning for Best Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing hyperparameter tuning for XGBoost...\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "\n",
      "Best parameters: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 300, 'subsample': 1.0}\n",
      "Best CV score: 0.9546\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for XGBoost (usually performs best)\n",
    "print(\"Performing hyperparameter tuning for XGBoost...\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_base = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "grid_search = GridSearchCV(\n",
    "    xgb_base, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_xgb = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Ensemble Model - Voting Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ensemble model...\n",
      "Ensemble CV accuracy: 0.9575 (+/- 0.0120)\n"
     ]
    }
   ],
   "source": [
    "# Create ensemble of best performing models\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', best_xgb if 'best_xgb' in locals() else xgb.XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42, eval_metric='logloss')),\n",
    "        ('rf', RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42, class_weight='balanced', n_jobs=-1)),\n",
    "        ('lr', LogisticRegression(max_iter=2000, random_state=42, class_weight='balanced', C=1.0))\n",
    "    ],\n",
    "    voting='soft',  # Use probability voting\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training ensemble model...\")\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate ensemble\n",
    "ensemble_scores = cross_val_score(ensemble, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"Ensemble CV accuracy: {ensemble_scores.mean():.4f} (+/- {ensemble_scores.std()*2:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Model Evaluation on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best XGBoost Performance ===\n",
      "Accuracy: 0.9599\n",
      "Precision: 0.9770\n",
      "Recall: 0.9413\n",
      "F1-Score: 0.9588\n",
      "\n",
      "Confusion Matrix:\n",
      "[[763  17]\n",
      " [ 45 721]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       780\n",
      "           1       0.98      0.94      0.96       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.96      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "\n",
      "=== Ensemble Performance ===\n",
      "Accuracy: 0.9638\n",
      "Precision: 0.9876\n",
      "Recall: 0.9386\n",
      "F1-Score: 0.9625\n",
      "\n",
      "Confusion Matrix:\n",
      "[[771   9]\n",
      " [ 47 719]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       780\n",
      "           1       0.99      0.94      0.96       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.97      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train final models and evaluate on test set\n",
    "final_models = {\n",
    "    'Best XGBoost': best_xgb if 'best_xgb' in locals() else xgb.XGBClassifier(n_estimators=300, max_depth=6, learning_rate=0.1, random_state=42, eval_metric='logloss'),\n",
    "    'Ensemble': ensemble\n",
    "}\n",
    "\n",
    "final_results = {}\n",
    "\n",
    "for name, model in final_models.items():\n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "    \n",
    "    final_results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n=== {name} Performance ===\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Best Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Ensemble\n",
      "Accuracy: 0.9638\n",
      "\n",
      "Model saved to D:/mental_health_detector\\models\\mental_health_model_improved.pkl\n",
      "Vectorizer saved to D:/mental_health_detector\\models\\tfidf_vectorizer_improved.pkl\n",
      "Feature selector saved to D:/mental_health_detector\\models\\feature_selector.pkl\n"
     ]
    }
   ],
   "source": [
    "# Find best model\n",
    "best_final_name = max(final_results, key=lambda x: final_results[x]['accuracy'])\n",
    "best_final_model = final_results[best_final_name]['model']\n",
    "\n",
    "print(f\"Best model: {best_final_name}\")\n",
    "print(f\"Accuracy: {final_results[best_final_name]['accuracy']:.4f}\")\n",
    "\n",
    "# Save model and vectorizer\n",
    "models_dir = os.path.join(base_dir, 'models')\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save improved model\n",
    "model_path = os.path.join(models_dir, 'mental_health_model_improved.pkl')\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(best_final_model, f)\n",
    "print(f\"\\nModel saved to {model_path}\")\n",
    "\n",
    "# Save vectorizer\n",
    "vectorizer_path = os.path.join(models_dir, 'tfidf_vectorizer_improved.pkl')\n",
    "with open(vectorizer_path, 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "print(f\"Vectorizer saved to {vectorizer_path}\")\n",
    "\n",
    "# Save selector if used\n",
    "if 'selector' in locals():\n",
    "    selector_path = os.path.join(models_dir, 'feature_selector.pkl')\n",
    "    with open(selector_path, 'wb') as f:\n",
    "        pickle.dump(selector, f)\n",
    "    print(f\"Feature selector saved to {selector_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
